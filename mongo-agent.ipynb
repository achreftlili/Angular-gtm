{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erLbtxhaeYZz"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mongodb-developer/ai-agents-lab-notebooks/blob/main/notebook_template.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDtmA5uzeYaT"
      },
      "source": [
        "[![Lab Documentation and Solutions](https://img.shields.io/badge/Lab%20Documentation%20and%20Solutions-purple)](https://mongodb-developer.github.io/ai-agents-lab/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kMALXaMv-MS"
      },
      "source": [
        "# Step 1: Install libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxTXczeTghzU"
      },
      "outputs": [],
      "source": [
        "! pip install -qU pymongo langchain langchain-fireworks langgraph sentence_transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM8rg08YhqZe"
      },
      "source": [
        "# Step 2: Setup prerequisites\n",
        "\n",
        "Replace:\n",
        "\n",
        "- `<MONGODB_URI>` with your **MongoDB connection string**\n",
        "- `<FIREWORKS_API_KEY>` with your **Fireworks API key**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41lqv3bneYa-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pymongo import MongoClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXLWCWEghuOX"
      },
      "outputs": [],
      "source": [
        "# Retain the quotes (\"\") when pasting the URI\n",
        "MONGODB_URI = \"<MONGODB_URI>\"\n",
        "# Initialize a MongoDB Python client\n",
        "mongodb_client = MongoClient(MONGODB_URI, appname=\"devrel.workshop.agents\")\n",
        "# Check the connection to the server\n",
        "mongodb_client.admin.command(\"ping\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnsQCKMbeYbB"
      },
      "source": [
        "### **Do not change the values assigned to the variables below**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysC6kAU6eYbD"
      },
      "outputs": [],
      "source": [
        "#  Database name\n",
        "DB_NAME = \"mongodb_agents_lab\"\n",
        "# Name of the collection with full articles- used for summarization\n",
        "FULL_COLLECTION_NAME = \"full_articles\"\n",
        "# Name of the collection for vector search- used for Q&A, recommending articles to read\n",
        "VS_COLLECTION_NAME = \"chunked_articles\"\n",
        "# Name of the vector search index\n",
        "VS_INDEX_NAME = \"vector_index\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5GBwTmfeYbE"
      },
      "outputs": [],
      "source": [
        "# Retain the quotes (\"\") when pasting the API key\n",
        "os.environ[\"FIREWORKS_API_KEY\"] = \"<FIREWORKS_API_KEY>\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUf3jtFzO4-V"
      },
      "source": [
        "# Step 3: Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heSuYhb-eYbH"
      },
      "outputs": [],
      "source": [
        "from urllib.parse import quote\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gjjhWTQeYbI"
      },
      "outputs": [],
      "source": [
        "IMPORT_URL = \"https://sid3czleh6uub3cl7f3tjjaile0rnzui.lambda-url.us-west-2.on.aws/\"\n",
        "encoded_url = quote(MONGODB_URI)\n",
        "response = requests.get(f\"{IMPORT_URL}?uri={encoded_url}\")\n",
        "status_code = response.status_code\n",
        "if status_code == 200:\n",
        "    print(\"Data ingested successfully into MongoDB\")\n",
        "else:\n",
        "    print(f\"Error code {status_code}: Error ingesting data into MongoDB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmdRL3sLeYbf"
      },
      "source": [
        "# Step 4: Create a vector search index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT38-Fk6eYbg"
      },
      "outputs": [],
      "source": [
        "# Create vector index definition specifying:\n",
        "# path: Path to the embeddings field\n",
        "# numDimensions: Number of embedding dimensions- depends on the embedding model used\n",
        "# similarity: Similarity metric. One of cosine, euclidean, dotProduct.\n",
        "model = {\n",
        "    \"name\": VS_INDEX_NAME,\n",
        "    \"type\": \"vectorSearch\",\n",
        "    \"definition\": {\n",
        "        \"fields\": [\n",
        "            {\n",
        "                \"type\": \"vector\",\n",
        "                \"path\": \"embedding\",\n",
        "                \"numDimensions\": 384,\n",
        "                \"similarity\": \"cosine\",\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eo0TajDeYbh"
      },
      "source": [
        "ðŸ“š https://pymongo.readthedocs.io/en/stable/tutorial.html#getting-a-collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ljgW-SQeYbh"
      },
      "outputs": [],
      "source": [
        "# Connect to the collection to perform vector search against.\n",
        "# Use the `mongodb_client` and database and collection variables defined in Step 2.\n",
        "vs_collection = <CODE_BLOCK_1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWLb32lFeYbi"
      },
      "source": [
        "ðŸ“š https://pymongo.readthedocs.io/en/stable/api/pymongo/collection.html#pymongo.collection.Collection.create_search_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbKW_cG1eYbi"
      },
      "outputs": [],
      "source": [
        "# Create a vector search index with the above `model` for the `vs_collection` collection\n",
        "<CODE_BLOCK_2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZfheX5FiIhU"
      },
      "source": [
        "# Step 5: Create agent tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DUAIimxeYbn"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import tool\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEb1dnSMeYbo"
      },
      "source": [
        "### Vector Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvZZ-2gdeYbo"
      },
      "outputs": [],
      "source": [
        "# Load the `gte-small` model using the Sentence Transformers library\n",
        "embedding_model = SentenceTransformer(\"thenlper/gte-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWQiVqh1eYbp"
      },
      "source": [
        "ðŸ“š https://huggingface.co/thenlper/gte-small#usage (See \"Use with sentence-transformers\" under Usage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzV_halkeYbq"
      },
      "outputs": [],
      "source": [
        "# Define a function that takes a piece of text (`text`) as input, embeds it using the `embedding_model` instantiated above and returns the embedding as a list\n",
        "# An array can be converted to a list using the `tolist()` method\n",
        "def get_embedding(text: str) -> List[float]:\n",
        "    \"\"\"\n",
        "    Generate the embedding for a piece of text.\n",
        "\n",
        "    Args:\n",
        "        text (str): Text to embed.\n",
        "\n",
        "    Returns:\n",
        "        List[float]: Embedding of the text as a list.\n",
        "    \"\"\"\n",
        "    embedding = embedding_model.encode(text)\n",
        "\n",
        "    return embedding.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3bA5_4MeYbw"
      },
      "source": [
        "ðŸ“š https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#ann-examples (Refer to the \"Basic Example\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaxXl7UueYbx"
      },
      "outputs": [],
      "source": [
        "# Define a tool to retrieve relevant documents for a user query using vector search\n",
        "@tool\n",
        "def get_information_for_question_answering(user_query: str) -> str:\n",
        "    \"\"\"\n",
        "    Retrieve information using vector search to answer a user query.\n",
        "\n",
        "    Args:\n",
        "    user_query (str): The user's query string.\n",
        "\n",
        "    Returns:\n",
        "    str: The retrieved information formatted as a string.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate embedding for the `user_query` using the `get_embedding` function defined above\n",
        "    query_embedding = get_embedding(user_query)\n",
        "\n",
        "    # Define an aggregation pipeline consisting of a $vectorSearch stage, followed by a $project stage\n",
        "    # Set the number of candidates to 150 and only return the top 5 documents from the vector search\n",
        "    # In the $project stage, exclude the `_id` field and include only the `body` field and `vectorSearchScore`\n",
        "    # NOTE: Use variables defined previously for the `index`, `queryVector` and `path` fields in the $vectorSearch stage\n",
        "    pipeline = [\n",
        "                  {\n",
        "                      \"$vectorSearch\": {\n",
        "                          \"index\": VS_INDEX_NAME,\n",
        "                          \"path\": \"embedding\",\n",
        "                          \"queryVector\": query_embedding,\n",
        "                          \"numCandidates\": 150,\n",
        "                          \"limit\": 5,\n",
        "                      }\n",
        "                  },\n",
        "                  {\n",
        "                      \"$project\": {\n",
        "                          \"_id\": 0,\n",
        "                          \"body\": 1,\n",
        "                          \"score\": {\"$meta\": \"vectorSearchScore\"},\n",
        "                      }\n",
        "                  },\n",
        "              ]\n",
        "\n",
        "    # Execute the aggregation `pipeline` against the `vs_collection` collection and store the results in `results`\n",
        "    results = vs_collection.aggregate(pipeline)\n",
        "    # Concatenate the results into a string\n",
        "    context = \"\\n\\n\".join([doc.get(\"body\") for doc in results])\n",
        "    return context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeRX211GeYby"
      },
      "source": [
        "### Get article content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWjbLUsEeYbz"
      },
      "source": [
        "ðŸ“š https://pymongo.readthedocs.io/en/stable/tutorial.html#getting-a-collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yCEYpJheYbz"
      },
      "outputs": [],
      "source": [
        "# Connect to the collection to get articles from for summarization.\n",
        "# Use the `mongodb_client` and database and collection variables defined in Step 2.\n",
        "full_collection = mongodb_client[DB_NAME][FULL_COLLECTION_NAME]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCHGbjy8eYbz"
      },
      "source": [
        "ðŸ“š https://www.mongodb.com/docs/manual/reference/method/db.collection.findOne/#return-all-but-the-excluded-fields"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyFeRw2YeYb0"
      },
      "outputs": [],
      "source": [
        "# Define a tool to retrieve full article content for summarization\n",
        "@tool\n",
        "def get_article_content_for_summarization(user_query: str) -> str:\n",
        "    \"\"\"\n",
        "    Retrieve article content based on provided title.\n",
        "\n",
        "    Args:\n",
        "    user_query (str): The user's query string i.e. title of the article.\n",
        "\n",
        "    Returns:\n",
        "    str: The content of the article.\n",
        "    \"\"\"\n",
        "    # Query the documents where the `title` field is equal to the `user_query`\n",
        "    query = {\"title\": user_query}\n",
        "    # Only return the `body` field from the retrieved documents.\n",
        "    # NOTE: Set fields to include to 1, those to exclude to 0. `_id` is included by default, so exclude that.\n",
        "    projection = {\"_id\": 0, \"body\": 1}\n",
        "    # Use the `query` and `projection` with the `find_one` method\n",
        "    # to get the `body` of the document with `title` equal to the `user_query` from the `full_collection` collection\n",
        "    document = full_collection.find_one(query, projection)\n",
        "    if document:\n",
        "        return document[\"body\"]\n",
        "    else:\n",
        "        return \"Article not found\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkxcTLmveYb1"
      },
      "outputs": [],
      "source": [
        "# Create the list of tools\n",
        "tools = [\n",
        "    get_information_for_question_answering,\n",
        "    get_article_content_for_summarization,\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGPUZD_3eYb1"
      },
      "source": [
        "### Test out the tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n62meCN5eYb2"
      },
      "outputs": [],
      "source": [
        "# Test out the `get_information_for_question_answering` tool with the query \"What are Atlas Triggers?\"\n",
        "get_information_for_question_answering.invoke(\"What are Atlas Triggers?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8couyNFeYb3"
      },
      "outputs": [],
      "source": [
        "# Test out the `get_article_content_for_summarization` tool with article name \"Using MongoDB Atlas Triggers to Summarize Airbnb Reviews with OpenAI\"\n",
        "get_article_content_for_summarization.invoke(\n",
        "    \"How to Model Your Documents for Vector Search\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFwjHhh0eYb3"
      },
      "source": [
        "# Step 6: Define graph state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqSmJEuIeYb3"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "from typing_extensions import TypedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG0GtsDAeYb4"
      },
      "outputs": [],
      "source": [
        "# Define the graph state\n",
        "# We are only tracking chat messages but you can track other attributes as well\n",
        "class GraphState(TypedDict):\n",
        "    messages: Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzEMm03yeYcg"
      },
      "source": [
        "# Step 7: Instantiate the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zhJNBNmeYco"
      },
      "outputs": [],
      "source": [
        "from langchain_fireworks import ChatFireworks\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qW85lSneYcp"
      },
      "source": [
        "ðŸ“š https://python.langchain.com/docs/integrations/chat/fireworks/#instantiation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCRao9kneYcp"
      },
      "outputs": [],
      "source": [
        "# Instantiate a Fireworks AI LLM using the `ChatFireworks` class\n",
        "# Params:\n",
        "# model: Model name i.e. \"accounts/fireworks/models/firefunction-v2\"\n",
        "# temperature: 0.0\n",
        "llm = ChatFireworks(model=\"accounts/fireworks/models/firefunction-v2\", temperature=0.0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_UM6M94eYct"
      },
      "outputs": [],
      "source": [
        "# Create a Chain-of-Thought (CoT) prompt template for the agent.\n",
        "# This includes a system prompt and a placeholder for `messages`\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"You are a helpful AI assistant.\"\n",
        "            \" You are provided with tools to answer questions and summarize articles related to MongoDB.\"\n",
        "            \" Think step-by-step and use these tools to get the information required to answer the user query.\"\n",
        "            \" Do not re-run tools unless absolutely necessary.\"\n",
        "            \" If you are not able to get enough information using the tools, reply with I DON'T KNOW.\"\n",
        "            \" You have access to the following tools: {tool_names}.\"\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YH32fMsKeYct"
      },
      "outputs": [],
      "source": [
        "# Partial the prompt template with the tool names\n",
        "prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnqEbIMYeYcw"
      },
      "source": [
        "ðŸ“š https://python.langchain.com/v0.1/docs/modules/model_io/chat/function_calling/#binding-tool-schemas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPzIKGhseYcx"
      },
      "outputs": [],
      "source": [
        "# Bind the `tools` to the `llm` instantiated above\n",
        "bind_tools = llm.bind_tools(tools)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQPbn_o2eYcx"
      },
      "source": [
        "ðŸ“š https://python.langchain.com/v0.1/docs/expression_language/primitives/sequence/#the-pipe-operator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8eSxXxfeYcy"
      },
      "outputs": [],
      "source": [
        "# Chain the `prompt` with the tool-bound llm using the `|` operator\n",
        "llm_with_tools = prompt | bind_tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lzo1AL16eYdH"
      },
      "outputs": [],
      "source": [
        "# Test that the LLM is making the right tool calls\n",
        "llm_with_tools.invoke(\n",
        "    [\"Give me a summary of the article How to Model Your Documents for Vector Search\"]\n",
        ").tool_calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1LzDgmVeYdH"
      },
      "outputs": [],
      "source": [
        "# Test that the LLM is making the right tool calls\n",
        "llm_with_tools.invoke([\"What are Atlas Triggers?\"]).tool_calls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO0wtqIzeYdH"
      },
      "source": [
        "# Step 8: Define graph nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9NjAwyIeYdH"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import ToolMessage\n",
        "from typing import Dict\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-ih_5zZeYdL"
      },
      "outputs": [],
      "source": [
        "# Define the agent node\n",
        "def agent(state: GraphState) -> Dict[str, List]:\n",
        "    \"\"\"\n",
        "    Agent node\n",
        "\n",
        "    Args:\n",
        "        state (GraphState): Graph state\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, List]: Updates to messages\n",
        "    \"\"\"\n",
        "    # Get the messages from the graph `state`\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    # Invoke `llm_with_tools` with `messages` using the `invoke` method\n",
        "    # HINT: See Step 7 for how to invoke `llm_with_tools`\n",
        "    result = llm_with_tools.invoke(messages)\n",
        "    # Write `result` to the `messages` attribute of the graph state\n",
        "    return {\"messages\": [result]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8rsFAnOeYdM"
      },
      "outputs": [],
      "source": [
        "# Create a map of tool name to tool call\n",
        "tools_by_name = {tool.name: tool for tool in tools}\n",
        "pprint(tools_by_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scA14HUXeYdN"
      },
      "outputs": [],
      "source": [
        "# Define tool node\n",
        "def tool_node(state: GraphState) -> Dict[str, List]:\n",
        "    \"\"\"\n",
        "    Tool node\n",
        "\n",
        "    Args:\n",
        "        state (GraphState): Graph state\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, List]: Updates to messages\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    # Get the list of tool calls from messages\n",
        "    tool_calls = state[\"messages\"][-1].tool_calls\n",
        "    # A tool_call looks as follows:\n",
        "    # {\n",
        "    #     \"name\": \"get_information_for_question_answering\",\n",
        "    #     \"args\": {\"user_query\": \"What are Atlas Triggers\"},\n",
        "    #     \"id\": \"call_H5TttXb423JfoulF1qVfPN3m\",\n",
        "    #     \"type\": \"tool_call\",\n",
        "    # }\n",
        "    # Iterate through `tool_calls`\n",
        "    for tool_call in tool_calls:\n",
        "        # Get the tool from `tools_by_name` using the `name` attribute of the `tool_call`\n",
        "        tool = tools_by_name[tool_call[\"name\"]]\n",
        "        # Invoke the `tool` using the `args` attribute of the `tool_call`\n",
        "        # HINT: See previous line to see how to extract attributes from `tool_call`\n",
        "        observation = tool.invoke(tool_call[\"args\"])\n",
        "        # Append the result of executing the tool to the `result` list as a ToolMessage\n",
        "        # The `content` of the message is `observation` i.e. result of the tool call\n",
        "        # The `tool_call_id` can be obtained from the `tool_call`\n",
        "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
        "    # Write `result` to the `messages` attribute of the graph state\n",
        "    return {\"messages\": result}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7KJEVINeYdP"
      },
      "source": [
        "# Step 9: Define conditional edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9s3BvY3neYdQ"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Twbugl1OeYdR"
      },
      "outputs": [],
      "source": [
        "# Define conditional routing function\n",
        "def route_tools(state: GraphState):\n",
        "    \"\"\"\n",
        "    Use in the conditional_edge to route to the tool node if the last message\n",
        "    has tool calls. Otherwise, route to the end.\n",
        "    \"\"\"\n",
        "    # Get messages from graph state\n",
        "    messages = state.get(\"messages\", [])\n",
        "    if len(messages) > 0:\n",
        "        # Get the last AI message from messages\n",
        "        ai_message = messages[-1]\n",
        "    else:\n",
        "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
        "    # Check if the last message has tool calls\n",
        "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
        "        # If yes, return \"tools\"\n",
        "        return \"tools\"\n",
        "    # If no, return END\n",
        "    return END"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oShT5p86eYdR"
      },
      "source": [
        "# Step 10: Build the graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q2wsdtaeYdR"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START\n",
        "from IPython.display import Image, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JPp3MIjeYdS"
      },
      "outputs": [],
      "source": [
        "# Instantiate the graph\n",
        "graph = StateGraph(GraphState)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxpjRzkIeYdS"
      },
      "source": [
        "ðŸ“š https://blog.langchain.dev/langgraph/#nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLDHHBQbeYdS"
      },
      "outputs": [],
      "source": [
        "# Add nodes to the `graph` using the `add_node` function\n",
        "# Add a `agent` node. The `agent` node should run the `agent` function\n",
        "graph.add_node(\"agent\", agent)\n",
        "# Add a `tools` node. The `tools` node should run the `tool_node` function\n",
        "graph.add_node(\"tools\", tool_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jENUdJhVeYdS"
      },
      "source": [
        "ðŸ“š https://langchain-ai.github.io/langgraph/concepts/low_level/#normal-edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVrfof2aeYdT"
      },
      "outputs": [],
      "source": [
        "# Add fixed edges to the `graph` using the `add_edge` method\n",
        "# Add an edge from the START node to the `agent` node\n",
        "graph.add_edge(START, \"agent\")\n",
        "# Add an edge from the `tools` node to the `agent` node\n",
        "graph.add_edge(\"tools\", \"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyhNkkdUeYdT"
      },
      "source": [
        "ðŸ“š https://langchain-ai.github.io/langgraph/concepts/low_level/#conditional-edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPDz1o4TeYdT"
      },
      "outputs": [],
      "source": [
        "# Use the `add_conditional_edges` method to add a conditional edge from the `agent` node to the `tools` node\n",
        "# based on the output of the `route_tools` function\n",
        "graph.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    route_tools,\n",
        "    {\"tools\": \"tools\", END: END},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Li0v2u3feYdU"
      },
      "outputs": [],
      "source": [
        "# Compile the `graph`\n",
        "app = graph.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEiJt7x0eYdU"
      },
      "outputs": [],
      "source": [
        "# Visualize the graph\n",
        "try:\n",
        "    display(Image(app.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGB6wLX5eYdU"
      },
      "source": [
        "# Step 11: Execute the graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxnHG1ONeYdV"
      },
      "outputs": [],
      "source": [
        "# Stream outputs from the graph as they pass through its nodes\n",
        "def execute_graph(user_input: str) -> None:\n",
        "    \"\"\"\n",
        "    Stream outputs from the graph\n",
        "\n",
        "    Args:\n",
        "        user_input (str): User query string\n",
        "    \"\"\"\n",
        "    # Add user input to the messages attribute of the graph state\n",
        "    # The role of the message should be \"user\" and content should be `user_input`\n",
        "    input = {\"messages\": [(\"user\", user_input)]}\n",
        "    # Pass input to the graph and stream the outputs\n",
        "    for output in app.stream(input):\n",
        "        for key, value in output.items():\n",
        "            print(f\"Node {key}:\")\n",
        "            print(value)\n",
        "    print(\"---FINAL ANSWER---\")\n",
        "    print(value[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLvVUHZweYdy"
      },
      "outputs": [],
      "source": [
        "# Test the graph execution to view end-to-end flow\n",
        "execute_graph(\"What are MongoDB Atlas Triggers?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qYFAeQmeYdz"
      },
      "outputs": [],
      "source": [
        "# Test the graph execution to view end-to-end flow\n",
        "execute_graph(\n",
        "    \"Give me a summary of the article titled How to Model Your Documents for Vector Search\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igPLeXUbeYd1"
      },
      "source": [
        "# Step 12: Add memory to the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w87bRsNgeYd2"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3-e7lH8eYd3"
      },
      "outputs": [],
      "source": [
        "# Initialize a local checkpointer\n",
        "memory = MemorySaver()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOLEtocEeYd-"
      },
      "outputs": [],
      "source": [
        "# Instantiate the graph with the checkpointer\n",
        "app = graph.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlZqRdn7eYd_"
      },
      "source": [
        "ðŸ“š https://langchain-ai.github.io/langgraph/concepts/persistence/#threads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfD5f1ngeYd_"
      },
      "outputs": [],
      "source": [
        "def execute_graph(thread_id: str, user_input: str) -> None:\n",
        "    \"\"\"\n",
        "    Stream outputs from the graph\n",
        "\n",
        "    Args:\n",
        "        thread_id (str): Thread ID for the checkpointer\n",
        "        user_input (str): User query string\n",
        "    \"\"\"\n",
        "    # Add user input to the messages attribute of the graph state\n",
        "    # The role of the message should be \"user\" and content should be `user_input`\n",
        "    input = {\"messages\": [(\"user\", user_input)]}\n",
        "    # Define a config containing the thread ID\n",
        "    config = <CODE_BLOCK_22>\n",
        "    # Pass `input` and `config` to the graph and stream outputs\n",
        "    for output in app.stream(input, config):\n",
        "        for key, value in output.items():\n",
        "            print(f\"Node {key}:\")\n",
        "            print(value)\n",
        "    print(\"---FINAL ANSWER---\")\n",
        "    print(value[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjgkgIiQeYd_"
      },
      "outputs": [],
      "source": [
        "# Test graph execution with thread ID\n",
        "execute_graph(\n",
        "    \"1\",\n",
        "    \"Give me a summary of the article titled How to Model Your Documents for Vector Search\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-szAnqDeYeA"
      },
      "outputs": [],
      "source": [
        "# Follow-up question to ensure message history works\n",
        "execute_graph(\n",
        "    \"1\",\n",
        "    \"What did I just ask you?\",\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "RM8rg08YhqZe",
        "UUf3jtFzO4-V",
        "Sm5QZdshwJLN"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}